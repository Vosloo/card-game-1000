{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, sys.path[0] + \"/src\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from config import *\n",
    "from background_factory import BackgroundFactory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInitialScansPath(test_set=False):\n",
    "    return Path(IMAGES_PATH, TEST if test_set else DATA, INPUT)\n",
    "\n",
    "\n",
    "def getUnlabeledCardsPath(test_set=False):\n",
    "    return Path(IMAGES_PATH, TEST if test_set else DATA, OUTPUT)\n",
    "\n",
    "\n",
    "def getLabeledCardsPath(test_set=False):\n",
    "    return Path(IMAGES_PATH, TEST if test_set else DATA, LABELED)\n",
    "\n",
    "\n",
    "def getAnnotationsPath(test_set=False):\n",
    "    return Path(IMAGES_PATH, TEST if test_set else DATA, ANNOTATIONS)\n",
    "\n",
    "\n",
    "def getContoursPath(test_set=False):\n",
    "    return Path(IMAGES_PATH, TEST if test_set else DATA, CONTOURS)\n",
    "\n",
    "\n",
    "def getClassMapping(test_set=False):\n",
    "    path = Path(IMAGES_PATH, CLASS_MAPPING)\n",
    "    if not path.is_file():\n",
    "        return None\n",
    "    return json.loads(path.read_text())\n",
    "\n",
    "\n",
    "def setClassMapping(dictionary, test_set=False):\n",
    "    path = Path(IMAGES_PATH, CLASS_MAPPING)\n",
    "    json_object = json.dumps(dictionary, indent=4)\n",
    "    with path.open(mode=\"w\") as f:\n",
    "        f.write(json_object)\n",
    "\n",
    "\n",
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "\n",
    "def get_font_size(text, height):\n",
    "    for font_scale in range(50, 1, -1):\n",
    "        text_size = cv2.getTextSize(\n",
    "            text,\n",
    "            fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "            fontScale=font_scale,\n",
    "            thickness=font_scale // 2,\n",
    "        )\n",
    "        new_size = text_size[0][1]\n",
    "        if new_size < height:\n",
    "            return font_scale, text_size[0]\n",
    "\n",
    "\n",
    "def displayOpencvImage(image, name, width=600):\n",
    "    resize_image = ResizeWithAspectRatio(image, width)\n",
    "    cv2.imshow(name, resize_image)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Downloading background images </h3> </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(IMAGES, BACKGROUNDS, BACKGROUNDS_PKL).exists():\n",
    "    !mkdir -p $IMAGES$BACKGROUNDS\n",
    "    !wget -O $IMAGES$BACKGROUNDS/backgrounds.tar.gz https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\n",
    "    !tar -xvf $IMAGES$BACKGROUNDS/backgrounds.tar.gz -C $IMAGES$BACKGROUNDS\n",
    "    !mv $IMAGES$BACKGROUNDS$DTD$IMAGES $IMAGES$BACKGROUNDS\n",
    "    !rm -r $IMAGES$BACKGROUNDS$DTD\n",
    "    !rm $IMAGES$BACKGROUNDS/backgrounds.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Process background images and pickle them </h3> </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of background images: 5640\n",
      "Background images saved in images/backgrounds/backgrounds.pkl\n"
     ]
    }
   ],
   "source": [
    "DTD_DIR = IMAGES + BACKGROUNDS + IMAGES\n",
    "\n",
    "bg_imgs = []\n",
    "for subdir in os.listdir(DTD_DIR):\n",
    "    for image in os.listdir(DTD_DIR + subdir):\n",
    "        if not image.endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        bg_imgs.append(DTD_DIR + subdir + \"/\" + image)\n",
    "\n",
    "print(\"Number of background images:\", len(bg_imgs))\n",
    "pickle.dump(bg_imgs, open(IMAGES + BACKGROUNDS + BACKGROUNDS_PKL, \"wb\"))\n",
    "print(\"Background images saved in\", IMAGES + BACKGROUNDS + BACKGROUNDS_PKL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Create data folder structure </center></h3>\n",
    "\n",
    "Scans of the cards should be put into input folder of either test or data (test if for testing purposes so you presumably want to put it in data collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [DATA, TEST]\n",
    "dirs = [ANNOTATIONS, INPUT, LABELED, OUTPUT, CONTOURS]\n",
    "\n",
    "for item_set in sets:\n",
    "    for item_dir in dirs:\n",
    "        Path(ROOT_PATH, IMAGES, SCANS, item_set, item_dir).mkdir(\n",
    "            parents=True, exist_ok=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Extracting cards from a scan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = False\n",
    "scans_path = getInitialScansPath(test_set)\n",
    "scans_out_path = getUnlabeledCardsPath(test_set)\n",
    "contours_path = getContoursPath(test_set)\n",
    "\n",
    "# Detection area threshold (compared to largest detected area)\n",
    "# Used to remove dust/dirt picked by scanner and detected by opencv findContours method\n",
    "AREA_THERSHOLD = 0.1\n",
    "nROI = 0\n",
    "\n",
    "for e, filepath in enumerate(scans_path.iterdir()):\n",
    "    image = cv2.imread(str(filepath))\n",
    "    overlay = image.copy()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "\n",
    "    # Find contours\n",
    "    contours = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "    # Removing unwanted contours below given threshold\n",
    "    # bounding_box is a Straight Bounding Rectangle (not rotated)\n",
    "    bounds = [\n",
    "        {\n",
    "            \"bounding_box\": cv2.boundingRect(cnt),\n",
    "            \"contour\": cnt,\n",
    "            \"area\": cv2.contourArea(cnt),\n",
    "        }\n",
    "        for cnt in contours\n",
    "    ]\n",
    "    maxROI = max(bounds, key=lambda x: x[\"area\"])\n",
    "    area_thereshold = AREA_THERSHOLD * maxROI[\"area\"]\n",
    "    bounds = [_bounds for _bounds in bounds if _bounds[\"area\"] > area_thereshold]\n",
    "\n",
    "    # Set font size\n",
    "    overlay_h, overlay_w = overlay.shape[:2]\n",
    "    rect_width = int(overlay_w * 0.05)\n",
    "    font_scale, (font_width, font_height) = get_font_size(str(e), rect_width)\n",
    "\n",
    "    # Iterate thorugh contours and filter for ROI\n",
    "    for _bounds in bounds:\n",
    "        rect = cv2.minAreaRect(_bounds[\"contour\"])\n",
    "        box = np.int0(cv2.boxPoints(rect))\n",
    "\n",
    "        W = rect[1][0]\n",
    "        H = rect[1][1]\n",
    "\n",
    "        x1 = np.min(box[:, 0])\n",
    "        x2 = np.max(box[:, 0])\n",
    "        y1 = np.min(box[:, 1])\n",
    "        y2 = np.max(box[:, 1])\n",
    "\n",
    "        x, y, w, h = _bounds[\"bounding_box\"]\n",
    "\n",
    "        center = (x + w // 2, y + h // 2)\n",
    "\n",
    "        rect_x, rect_y = (\n",
    "            center[0] - int((font_width / 2) * 1.2),\n",
    "            center[1] - int((font_height / 2) * 1.2),\n",
    "        )\n",
    "        cv2.rectangle(\n",
    "            overlay,\n",
    "            (rect_x, rect_y),\n",
    "            (rect_x + int(font_width * 1.2), rect_y + int(font_height * 1.2)),\n",
    "            (0, 0, 0),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            overlay,\n",
    "            str(nROI),\n",
    "            (x + w // 2 - font_width // 2, y + h // 2 + font_height // 2),\n",
    "            cv2.FONT_HERSHEY_DUPLEX,\n",
    "            font_scale,\n",
    "            (255, 255, 255),\n",
    "            font_scale,\n",
    "        )\n",
    "\n",
    "        # create new bounding box (nb)\n",
    "        nb_x = x1\n",
    "        nb_y = y1\n",
    "        nb_w = x2 - x1\n",
    "        nb_h = y2 - y1\n",
    "        x1, y1 = 0, 0\n",
    "        x2 -= nb_x\n",
    "        y2 -= nb_y\n",
    "\n",
    "        _bounds[\"contour\"][:, 0, 0] -= nb_x\n",
    "        _bounds[\"contour\"][:, 0, 1] -= nb_y\n",
    "\n",
    "        # Draw bounds overlay (not nessesary, just for overview)\n",
    "        cv2.drawContours(overlay, [box], -1, (0, 255, 0), 10)\n",
    "        # cv2.rectangle(overlay, (x, y), (x + w, y + h), (255, 0, 0), 10)\n",
    "        # cv2.rectangle(\n",
    "        #     overlay, (nb_x, nb_y), (nb_x + nb_w, nb_y + nb_h), (0, 0, 255), 10\n",
    "        # )\n",
    "\n",
    "        # Croping part with card\n",
    "        init_crop = image[nb_y : nb_y + nb_h, nb_x : nb_x + nb_w].copy()\n",
    "\n",
    "        # Remove backgorund (set it to transparent) by using mask of object extracted from contours\n",
    "        mask = np.zeros(init_crop.shape[:2], dtype=np.uint8)\n",
    "        cv2.drawContours(mask, [_bounds[\"contour\"]], 0, (255, 255, 255), cv2.FILLED)\n",
    "        mask_inv = 255 - mask\n",
    "        bg = np.zeros_like(init_crop)\n",
    "        image_masked = cv2.bitwise_and(init_crop, init_crop, mask=mask)\n",
    "        bg_masked = cv2.bitwise_and(bg, bg, mask=mask_inv)\n",
    "        no_bg_image = cv2.add(image_masked, bg_masked)\n",
    "\n",
    "        # Rotating detected card and cropping image to its size\n",
    "        rotated = False\n",
    "        angle = rect[2]\n",
    "\n",
    "        if angle < -45 or angle > 45:\n",
    "            angle += 90\n",
    "            rotated = True\n",
    "\n",
    "        center = (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "        size = (int(x2 - x1), int(y2 - y1))\n",
    "\n",
    "        M = cv2.getRotationMatrix2D((size[0] / 2, size[1] / 2), angle, 1.0)\n",
    "\n",
    "        b, g, r, a = cv2.split(no_bg_image)\n",
    "        bgr = cv2.merge((b, g, r))\n",
    "\n",
    "        croppedW = W if not rotated else H\n",
    "        croppedH = H if not rotated else W\n",
    "\n",
    "        image_split = []\n",
    "\n",
    "        # getRectSubPix doesn't support rgba therefore performing separatly on bgr and alpha channel\n",
    "        for layer in [bgr, a]:\n",
    "            cropped = cv2.getRectSubPix(layer, size, center)\n",
    "            cropped = cv2.warpAffine(cropped, M, size)\n",
    "            croppedRotated = cv2.getRectSubPix(\n",
    "                cropped, (int(croppedW), int(croppedH)), (size[0] / 2, size[1] / 2),\n",
    "            )\n",
    "            image_split.append(croppedRotated)\n",
    "        image_merged = cv2.merge(image_split)\n",
    "\n",
    "        # Rotate cards to standing position\n",
    "        # Assuming that every playing card height value is higher than its width\n",
    "\n",
    "        if image_merged.shape[0] < image_merged.shape[1]:\n",
    "            image_merged = cv2.rotate(image_merged, cv2.ROTATE_90_CLOCKWISE)\n",
    "        cv2.imwrite(str(scans_out_path.joinpath(f\"ROI_{nROI}.png\")), image_merged)\n",
    "\n",
    "        nROI += 1\n",
    "\n",
    "    cv2.rectangle(\n",
    "        overlay,\n",
    "        (overlay_w - int(font_width * 1.2), 0),\n",
    "        (overlay_w, int(font_width * 1.2)),\n",
    "        (0, 0, 0),\n",
    "        -1,\n",
    "    )\n",
    "    cv2.putText(\n",
    "        overlay,\n",
    "        str(e),\n",
    "        (overlay_w - int(font_width * 1.1), int(font_height * 1.1)),\n",
    "        cv2.FONT_HERSHEY_DUPLEX,\n",
    "        font_scale,\n",
    "        (0, 0, 255),\n",
    "        font_scale,\n",
    "    )\n",
    "\n",
    "    # Save contour detection to file in contours folder\n",
    "    cv2.imwrite(str(contours_path.joinpath(filepath.name)), overlay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Add mapping of class labels to values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = False\n",
    "\n",
    "card_values = [\"9\", \"10\", \"J\", \"Q\", \"K\", \"A\"]\n",
    "card_symbols = [\"H\", \"D\", \"C\", \"S\"]\n",
    "\n",
    "mapping = {\n",
    "    x + y: ex * 4 + ey\n",
    "    for ex, x in enumerate(card_values)\n",
    "    for ey, y in enumerate(card_symbols)\n",
    "}\n",
    "\n",
    "setClassMapping(mapping, test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Manually rename scanned cards one by one to proper form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's prefered to use second method\n",
    "\n",
    "# unlabeled_path = getUnlabeledCardsPath(test_set)\n",
    "# labeled_path = getLabeledCardsPath(test_set)\n",
    "\n",
    "# no_files = len(os.listdir(unlabeled_path))\n",
    "# size = 600, 600\n",
    "\n",
    "# for e, filepath in enumerate(unlabeled_path.iterdir()):\n",
    "#     image = Image.open(filepath)\n",
    "#     image.thumbnail(size)\n",
    "#     image.show(title=str(unlabeled_path.name))\n",
    "#     new_filename = input(f\"Image {e} out of {no_files}\\nEnter new file name: \")\n",
    "#     shutil.copy(str(filepath), str(labeled_path.joinpath(f\"{new_filename}.png\")))\n",
    "#     image.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>or do it in a batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For order of ROI look inside contours folder. Numbers on card match their ROI (filename with extracted card e.g ROI_1.png). ROI_labels list must match in size number of detected cards in all files and their order (otherwise it will be mismatched or simply fail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill ROI_labels to chosen set before running\n",
    "ROI_labels = [\n",
    "    \"9C\",\n",
    "    \"10S\",\n",
    "    \"9D\",\n",
    "    \"10H\",\n",
    "    \"9H\",\n",
    "    \"10C\",\n",
    "    \"10D\",\n",
    "    \"9S\",\n",
    "    \"KH\",\n",
    "    \"AD\",\n",
    "    \"KC\",\n",
    "    \"AC\",\n",
    "    \"KS\",\n",
    "    \"AH\",\n",
    "    \"KD\",\n",
    "    \"AS\",\n",
    "    \"QC\",\n",
    "    \"QH\",\n",
    "    \"QS\",\n",
    "    \"JH\",\n",
    "    \"JS\",\n",
    "    \"QD\",\n",
    "    \"JD\",\n",
    "    \"JC\",\n",
    "]\n",
    "\n",
    "test_set = False\n",
    "unlabeled_path = getUnlabeledCardsPath(test_set)\n",
    "labeled_path = getLabeledCardsPath(test_set)\n",
    "\n",
    "no_files = len(os.listdir(unlabeled_path))\n",
    "\n",
    "assert no_files == len(\n",
    "    ROI_labels\n",
    "), \"ROI_labels must be the same lenght as number of ROI files in output folder\"\n",
    "\n",
    "for e, filepath in enumerate(unlabeled_path.iterdir()):\n",
    "    image = cv2.imread(str(filepath), cv2.IMREAD_UNCHANGED)\n",
    "    resized_image = ResizeWithAspectRatio(image, height=350)\n",
    "    cv2.imwrite(str(labeled_path.joinpath(f\"{ROI_labels[e]}.png\")), resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Detect card corner symbols and add adequate labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = False\n",
    "show_contours = False\n",
    "labeled_path = getLabeledCardsPath(test_set)\n",
    "labels_path = getAnnotationsPath(test_set)\n",
    "\n",
    "mapping = getClassMapping(test_set)\n",
    "\n",
    "# Adding extra space (to combat scan/card messurment error margin)\n",
    "EXTRA_SPACE = 1\n",
    "\n",
    "# SYMBOL - number and symbol contained in corners of card\n",
    "# SYMBOL_VM - vertical margin (distance of symbol from closest edge top/bottom)\n",
    "# SYMBOL_HM - horizontal margin (distance of symbol from closest edge left/right)\n",
    "CARD_HEIGHT = 89\n",
    "CARD_WIDTH = 58\n",
    "SYMBOL_VM = 4 - EXTRA_SPACE\n",
    "SYMBOL_HM = 3 - EXTRA_SPACE\n",
    "SYMBOL_HEIGHT = 18 + 2.5 * EXTRA_SPACE\n",
    "SYMBOL_WIDTH = 6 + 2.5 * EXTRA_SPACE\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "for filepath in labeled_path.iterdir():\n",
    "    image = cv2.imread(str(filepath))\n",
    "    overlay = image.copy()\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Calculate vertical and horizontal ratio\n",
    "    v_ratio = h / CARD_HEIGHT\n",
    "    h_ratio = w / CARD_WIDTH\n",
    "\n",
    "    symbol_vm = int(v_ratio * SYMBOL_VM)\n",
    "    symbol_hm = int(h_ratio * SYMBOL_HM)\n",
    "    symbol_height = int(v_ratio * SYMBOL_HEIGHT)\n",
    "    symbol_width = int(h_ratio * SYMBOL_WIDTH)\n",
    "\n",
    "    x1 = symbol_hm\n",
    "    x2 = symbol_hm + symbol_width\n",
    "    x3 = w - symbol_hm - symbol_width\n",
    "    x4 = w - symbol_hm\n",
    "    y1 = symbol_vm\n",
    "    y2 = symbol_vm + symbol_height\n",
    "    y3 = h - symbol_vm - symbol_height\n",
    "    y4 = h - symbol_vm\n",
    "\n",
    "    # Bounding boxes of card symbols\n",
    "    boxes = [[x1, y1, x2, y2], [x1, y3, x2, y4], [x3, y1, x4, y2], [x3, y3, x4, y4]]\n",
    "    card = {\n",
    "        CLASS: filepath.stem,\n",
    "        WIDTH: w,\n",
    "        HEIGHT: h,\n",
    "        BOUNDING_BOXES: [],\n",
    "        HULL: [],\n",
    "    }\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        if show_contours:\n",
    "            cv2.rectangle(\n",
    "                overlay, box[:2], box[2:], (0, 0, 255), 2,\n",
    "            )\n",
    "\n",
    "        # Find contours in cropped image *containing card symbol\n",
    "        # *It works only if cropping image from scan was sucessfull\n",
    "        crop = image[box[1] : box[3], box[0] : box[2]].copy()\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        canny = cv2.Canny(blurred, 120, 255, 1)\n",
    "        dilate = cv2.dilate(canny, kernel, iterations=1)\n",
    "        contours = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "        # Select 2 largest contours (number and card symbol) and merge them\n",
    "        # contours = sorted(\n",
    "        #     [[c, cv2.contourArea(c)] for c in contours],\n",
    "        #     key=lambda x: x[1],\n",
    "        #     reverse=True,\n",
    "        # )[:2]\n",
    "        # cnt = np.concatenate([contours[0][0], contours[1][0]])\n",
    "\n",
    "        # Use all contours\n",
    "        cnt = np.concatenate(contours)\n",
    "\n",
    "        cnt[:, 0, 0] += box[0]\n",
    "        cnt[:, 0, 1] += box[1]\n",
    "\n",
    "        bounding_box = cv2.boundingRect(cnt)\n",
    "        x_br, y_br, w_br, h_br = bounding_box\n",
    "\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        card[BOUNDING_BOXES].append([a / b for a, b in zip(bounding_box, [w, h, w, h])])\n",
    "        card[HULL].append(np.squeeze(hull, axis=1))\n",
    "\n",
    "        if show_contours:\n",
    "            cv2.drawContours(overlay, [hull], 0, (0, 255, 0, 0.5), 5)\n",
    "            cv2.rectangle(\n",
    "                overlay, (x_br, y_br), (x_br + w_br, y_br + h_br), (255, 0, 0), 1\n",
    "            )\n",
    "\n",
    "    pickle.dump(card, labels_path.joinpath(f\"{filepath.stem}.pkl\").open(mode=\"wb\"))\n",
    "\n",
    "    if show_contours:\n",
    "        displayOpencvImage(overlay, \"overlay\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_path = getLabeledCardsPath(test_set)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8eaadffd43a9327e2ef83ca76a953c4de6e9a324ddd0c89dd9a49c573b13018b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('cv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
